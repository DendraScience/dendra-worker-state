{
    "source_defaults":
    {
        "queue_group": "prep",
        "sub_options":
        {
            "ack_wait": 60000,
            "durable_name": "20220614"
        }
    },
    "sources":
    [
        {
            "description": "CDFW: Prepare file import payload for writing to Influx",
            "error_subject": "cdfw.prep.v1.err.import.file",
            "ignore_errors": true,
            "preprocessing_expr":
            [
                "($org := context.org_slug ~> $safeName;",
                "$station := context.station ~> $safeName;",
                "$table := context.table ~> $safeName;",
                "$tags := ['org' & '$' & $org, 'station' & '$' & $station, 'table' & '$' & $table];",
                "$time := payload.time;",
                "$params := {'tags': $tags, 'time': $time};",
                "$options := {'database': 'station_' & $station, 'precision': 'ms'};",
                "$fields := payload ~> $deleteNulls ~> $deleteKeys(['time']);",
                "$points := [{'fields': $fields, 'measurement': 'source_' & $table, 'time': $time}];",
                "$payload := {'options': $options, 'points': $points};",
                "$ ~> |$|{'params': $params, 'payload': $payload}|;)"
            ],
            "pub_to_subject": "cdfw.prep.v1.out",
            "sub_to_subject": "cdfw.import.v1.out.file"
        },
        {
            "description": "CDFW: Prepare patched payload for writing to Influx",
            "error_subject": "cdfw.prep.v1.err.patch",
            "ignore_errors": true,
            "preprocessing_expr":
            [
                "($org := context.org_slug ~> $safeName;",
                "$station := context.station ~> $safeName;",
                "$table := context.table ~> $safeName;",
                "$tags := ['org' & '$' & $org, 'station' & '$' & $station, 'table' & '$' & $table];",
                "$time := payload.time;",
                "$params := {'tags': $tags, 'time': $time};",
                "$options := {'database': 'station_' & $station, 'precision': 'ms'};",
                "$fields := payload ~> $deleteNulls ~> $deleteKeys(['time']);",
                "$points := [{'fields': $fields, 'measurement': 'source_' & $table, 'time': $time}];",
                "$payload := {'options': $options, 'points': $points};",
                "$ ~> |$|{'params': $params, 'payload': $payload}|;)"
            ],
            "pub_to_subject": "cdfw.prep.v1.out",
            "sub_to_subject": "cdfw.patch.v1.out"
        },
        {
            "description": "CHI: Prepare file import payload for writing to Influx",
            "error_subject": "chi.prep.v1.err.import.file",
            "ignore_errors": true,
            "preprocessing_expr":
            [
                "($org := context.org_slug ~> $safeName;",
                "$station := context.station ~> $safeName;",
                "$table := context.table ~> $safeName;",
                "$tags := ['org' & '$' & $org, 'station' & '$' & $station, 'table' & '$' & $table];",
                "$time := payload.time;",
                "$params := {'tags': $tags, 'time': $time};",
                "$options := {'database': 'station_' & $station, 'precision': 'ms'};",
                "$fields := payload ~> $deleteNulls ~> $deleteKeys(['time']);",
                "$points := [{'fields': $fields, 'measurement': 'source_' & $table, 'time': $time}];",
                "$payload := {'options': $options, 'points': $points};",
                "$ ~> |$|{'params': $params, 'payload': $payload}|;)"
            ],
            "pub_to_subject": "chi.prep.v1.out",
            "sub_to_subject": "chi.import.v1.out.file"
        },
        {
            "description": "ERCZO: Prepare file import payload for writing to Influx",
            "error_subject": "erczo.prep.v1.err.import.file",
            "ignore_errors": true,
            "preprocessing_expr":
            [
                "($org := context.org_slug ~> $safeName;",
                "$station := context.station ~> $safeName;",
                "$table := context.table ~> $safeName;",
                "$tags := ['org' & '$' & $org, 'station' & '$' & $station, 'table' & '$' & $table];",
                "$time := payload.time;",
                "$params := {'tags': $tags, 'time': $time};",
                "$options := {'database': 'station_' & $station, 'precision': 'ms'};",
                "$fields := payload ~> $deleteNulls ~> $deleteKeys(['time', 'DatastreamID']) ~> $mapValues(function($v, $k) { $contains($k, /_flag/i) ? $string($v) : $v });",
                "$tagset := {'DatastreamID': $number(payload.DatastreamID)};",
                "$tagset := $count($keys($tagset)) ? $tagset : undefined;",
                "$points := [{'fields': $fields, 'tags': $tagset, 'measurement': 'source_' & $table, 'time': $time}];",
                "$payload := {'options': $options, 'points': $points};",
                "$ ~> |$|{'params': $params, 'payload': $payload}|;)"
            ],
            "pub_to_subject": "erczo.prep.v1.out",
            "sub_to_subject": "erczo.import.v1.out.file"
        },
        {
            "description": "Fog RNS: Prepare file import payload for writing to Influx",
            "error_subject": "fogrns.prep.v1.err.import.file",
            "ignore_errors": true,
            "preprocessing_expr":
            [
                "($org := context.org_slug ~> $safeName;",
                "$station := context.station ~> $safeName;",
                "$table := context.table ~> $safeName;",
                "$tags := [$org ? 'org' & '$' & $org : undefined, $station ? 'station' & '$' & $station : undefined, $table ? 'table' & '$' & $table : undefined];",
                "$ms := $toMillis('1970-01-01 ' & payload.Time, '[Y0001]-[M01]-[D01] [h#1]:[m01]:[s01] [P]');",
                "$time := payload.time + $ms;",
                "$params := {'tags': $tags, 'time': $time};",
                "$source := context.source ~> $split('/');",
                "$database := $source[2] ? $source[2] ~> $safeName : $station ? 'station_' & $station : 'database_unknown';",
                "$meas := $source[3] ? $source[3] ~> $safeName : $table ? 'source_' & $table : 'unknown';",
                "$options := {'database': $database, 'precision': 'ms'};",
                "$fields := payload ~> $deleteNulls ~> $deleteKeys(['time', 'Time']);",
                "$points := [{'fields': $fields, 'measurement': $meas, 'time': $time}];",
                "$payload := {'options': $options, 'points': $points};",
                "$ ~> |$|{'params': $params, 'payload': $payload}|;)"
            ],
            "pub_to_subject": "fogrns.prep.v1.out",
            "sub_to_subject": "fogrns.import.v1.out.file"
        },
        {
            "description": "Pepperwood: Prepare file import payload for writing to Influx",
            "error_subject": "pepperwood.prep.v1.err.import.file",
            "ignore_errors": true,
            "preprocessing_expr":
            [
                "($org := context.org_slug ~> $safeName;",
                "$station := context.station ~> $safeName;",
                "$table := context.table ~> $safeName;",
                "$tags := ['org' & '$' & $org, 'station' & '$' & $station, 'table' & '$' & $table];",
                "$time := payload.time;",
                "$params := {'tags': $tags, 'time': $time};",
                "$options := {'database': 'station_' & $station, 'precision': 'ms'};",
                "$fields := payload ~> $deleteNulls ~> $deleteKeys(['time']);",
                "$points := [{'fields': $fields, 'measurement': 'source_' & $table, 'time': $time}];",
                "$payload := {'options': $options, 'points': $points};",
                "$ ~> |$|{'params': $params, 'payload': $payload}|;)"
            ],
            "pub_to_subject": "pepperwood.prep.v1.out",
            "sub_to_subject": "pepperwood.import.v1.out.file"
        },
        {
            "description": "PREP: Prepare file import payload for writing to Influx",
            "error_subject": "prep.prep.v1.err.import.file",
            "ignore_errors": true,
            "preprocessing_expr":
            [
                "($org := context.org_slug ~> $safeName;",
                "$station := context.station ~> $safeName;",
                "$table := context.table ~> $safeName;",
                "$tags := ['org' & '$' & $org, 'station' & '$' & $station, 'table' & '$' & $table];",
                "$time := payload.time;",
                "$params := {'tags': $tags, 'time': $time};",
                "$options := {'database': 'station_' & $station, 'precision': 'ms'};",
                "$fields := payload ~> $deleteNulls ~> $deleteKeys(['time']);",
                "$points := [{'fields': $fields, 'measurement': 'source_' & $table, 'time': $time}];",
                "$payload := {'options': $options, 'points': $points};",
                "$ ~> |$|{'params': $params, 'payload': $payload}|;)"
            ],
            "pub_to_subject": "prep.prep.v1.out",
            "sub_to_subject": "prep.import.v1.out.file"
        },
        {
            "description": "TNC: Prepare file import payload for writing to Influx",
            "error_subject": "tnc.prep.v1.err.import.file",
            "ignore_errors": true,
            "preprocessing_expr":
            [
                "($org := context.org_slug ~> $safeName;",
                "$station := context.station ~> $safeName;",
                "$table := context.table ~> $safeName;",
                "$tags := [$org ? 'org' & '$' & $org : undefined, $station ? 'station' & '$' & $station : undefined, $table ? 'table' & '$' & $table : undefined];",
                "$time := payload.time;",
                "$params := {'tags': $tags, 'time': $time};",
                "$source := context.source ~> $split('/');",
                "$database := $source[2] ? $source[2] ~> $safeName : $station ? 'station_' & $station : 'database_unknown';",
                "$meas := $source[3] ? $source[3] ~> $safeName : $table ? 'source_' & $table : 'unknown';",
                "$options := {'database': $database, 'precision': 'ms'};",
                "$fields := payload ~> $deleteNulls ~> $deleteKeys(['time']);",
                "$points := [{'fields': $fields, 'measurement': $meas, 'time': $time}];",
                "$payload := {'options': $options, 'points': $points};",
                "$ ~> |$|{'params': $params, 'payload': $payload}|;)"
            ],
            "pub_to_subject": "tnc.prep.v1.out",
            "sub_to_subject": "tnc.import.v1.out.file"
        },
        {
            "description": "UCANR: Prepare file import payload for writing to Influx",
            "error_subject": "ucanr.prep.v1.err.import.file",
            "ignore_errors": true,
            "preprocessing_expr":
            [
                "($org := context.org_slug ~> $safeName;",
                "$station := context.station ~> $safeName;",
                "$table := context.table ~> $safeName;",
                "$tags := ['org' & '$' & $org, 'station' & '$' & $station, 'table' & '$' & $table];",
                "$time := payload.time;",
                "$params := {'tags': $tags, 'time': $time};",
                "$options := {'database': 'station_' & $station, 'precision': 'ms'};",
                "$fields := payload ~> $deleteNulls ~> $deleteKeys(['time']);",
                "$points := [{'fields': $fields, 'measurement': 'source_' & $table, 'time': $time}];",
                "$payload := {'options': $options, 'points': $points};",
                "$ ~> |$|{'params': $params, 'payload': $payload}|;)"
            ],
            "pub_to_subject": "ucanr.prep.v1.out",
            "sub_to_subject": "ucanr.import.v1.out.file"
        },
        {
            "description": "UCNRS: Prepare file import payload for writing to Influx",
            "error_subject": "ucnrs.prep.v1.err.import.file",
            "ignore_errors": true,
            "preprocessing_expr":
            [
                "($org := context.org_slug ~> $safeName;",
                "$station := context.station ~> $safeName;",
                "$table := context.table ~> $safeName;",
                "$tags := ['org' & '$' & $org, 'station' & '$' & $station, 'table' & '$' & $table];",
                "$time := payload.time;",
                "$params := {'tags': $tags, 'time': $time};",
                "$options := {'database': 'station_' & $station, 'precision': 'ms'};",
                "$fields := payload ~> $deleteNulls ~> $deleteKeys(['time', 'DatastreamID']) ~> $mapValues(function($v, $k) { $contains($k, /_flag/i) ? $string($v) : $v });",
                "$tagset := {'DatastreamID': $number(payload.DatastreamID)};",
                "$tagset := $count($keys($tagset)) ? $tagset : undefined;",
                "$points := [{'fields': $fields, 'tags': $tagset, 'measurement': 'source_' & $table, 'time': $time}];",
                "$payload := {'options': $options, 'points': $points};",
                "$ ~> |$|{'params': $params, 'payload': $payload}|;)"
            ],
            "pub_to_subject": "ucnrs.prep.v1.out",
            "sub_to_subject": "ucnrs.import.v1.out.file"
        }
    ]
}